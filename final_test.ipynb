{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a7f33cfe4fd643f08783c22c3a921279": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ac10e0f757044bd39f373044a4b60103",
              "IPY_MODEL_2a78e6f0cab94eb9b456966ab028af9d",
              "IPY_MODEL_550e5a6431b34539bbe91ddfd0a484b0"
            ],
            "layout": "IPY_MODEL_43df045ac42b4717a51c09b68fba2cbf"
          }
        },
        "ac10e0f757044bd39f373044a4b60103": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68eda61cdfd949b4a0b7d8b6a7575d04",
            "placeholder": "​",
            "style": "IPY_MODEL_0e6a0872ed154266af6f5a8c7680875e",
            "value": "100%"
          }
        },
        "2a78e6f0cab94eb9b456966ab028af9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b83a0f030d4497e8e196a2496162f4b",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0fcca2fbd197430f83fa0444fa3bc986",
            "value": 1
          }
        },
        "550e5a6431b34539bbe91ddfd0a484b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5afa6f2c493490fbe84a3f5f8dadfd4",
            "placeholder": "​",
            "style": "IPY_MODEL_430162f98ae5465090b276c2e35aabe3",
            "value": " 1/1 [00:05&lt;00:00,  5.11s/it]"
          }
        },
        "43df045ac42b4717a51c09b68fba2cbf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68eda61cdfd949b4a0b7d8b6a7575d04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e6a0872ed154266af6f5a8c7680875e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9b83a0f030d4497e8e196a2496162f4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0fcca2fbd197430f83fa0444fa3bc986": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a5afa6f2c493490fbe84a3f5f8dadfd4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "430162f98ae5465090b276c2e35aabe3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Workaround to install pystruct.\n",
        "!pip install --upgrade pip setuptools==57.5.0 \n",
        "!git clone https://github.com/pystruct/pystruct && cd pystruct\n",
        "!curl https://patch-diff.githubusercontent.com/raw/pystruct/pystruct/pull/221.patch | git apply\n",
        "!pip install pystruct/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LENyhb6A_gBp",
        "outputId": "c81faa05-a21b-459a-f82b-24da2d7aa3f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (21.1.3)\n",
            "Collecting pip\n",
            "  Downloading pip-22.3.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 5.3 MB/s \n",
            "\u001b[?25hCollecting setuptools==57.5.0\n",
            "  Downloading setuptools-57.5.0-py3-none-any.whl (819 kB)\n",
            "\u001b[K     |████████████████████████████████| 819 kB 48.0 MB/s \n",
            "\u001b[?25hInstalling collected packages: setuptools, pip\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 57.4.0\n",
            "    Uninstalling setuptools-57.4.0:\n",
            "      Successfully uninstalled setuptools-57.4.0\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 21.1.3\n",
            "    Uninstalling pip-21.1.3:\n",
            "      Successfully uninstalled pip-21.1.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.9.0 requires jedi>=0.10, which is not installed.\u001b[0m\n",
            "Successfully installed pip-22.3.1 setuptools-57.5.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pkg_resources"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pystruct'...\n",
            "remote: Enumerating objects: 6974, done.\u001b[K\n",
            "remote: Total 6974 (delta 0), reused 0 (delta 0), pack-reused 6974\u001b[K\n",
            "Receiving objects: 100% (6974/6974), 12.16 MiB | 20.61 MiB/s, done.\n",
            "Resolving deltas: 100% (4357/4357), done.\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 1260k    0 1260k    0     0  3036k      0 --:--:-- --:--:-- --:--:-- 3029k\n",
            "<stdin>:912: trailing whitespace.\n",
            " * \n",
            "<stdin>:915: trailing whitespace.\n",
            " * \n",
            "<stdin>:2642: trailing whitespace.\n",
            "      __pyx_t_3 = __Pyx_TypeCheck(__pyx_v_arg, __pyx_v_ndarray); \n",
            "<stdin>:2652: trailing whitespace.\n",
            "      __pyx_t_2 = __pyx_memoryview_check(__pyx_v_arg); \n",
            "<stdin>:2660: trailing whitespace.\n",
            "        __pyx_t_3 = __Pyx_TypeCheck(__pyx_v_arg_base, __pyx_v_ndarray); \n",
            "error: src/utils.c: No such file or directory\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Processing ./pystruct\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ad3\n",
            "  Downloading ad3-2.2.1-cp37-cp37m-manylinux1_x86_64.whl (668 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m668.9/668.9 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pystruct==0.3.2) (1.21.6)\n",
            "Requirement already satisfied: cvxopt in /usr/local/lib/python3.7/dist-packages (from pystruct==0.3.2) (1.3.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pystruct==0.3.2) (0.16.0)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from pystruct==0.3.2) (0.29.32)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from pystruct==0.3.2) (1.0.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pystruct==0.3.2) (1.7.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pystruct==0.3.2) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pystruct==0.3.2) (1.2.0)\n",
            "Building wheels for collected packages: pystruct\n",
            "  Building wheel for pystruct (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pystruct: filename=pystruct-0.3.2-cp37-cp37m-linux_x86_64.whl size=5974480 sha256=dde40d42faa11961faa80456d84964b2daad00d6d6eb7e0a9e0fdff538077899\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-duiyxwjt/wheels/10/49/65/894632af5d63c60358bcc4c15ebb989283f4be159b7f57a353\n",
            "Successfully built pystruct\n",
            "Installing collected packages: ad3, pystruct\n",
            "Successfully installed ad3-2.2.1 pystruct-0.3.2\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import xml.etree.ElementTree as et\n",
        "import json\n",
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "import matplotlib.pyplot as pp\n",
        "from google.colab import drive\n",
        "from tqdm.notebook import tqdm\n",
        "from google.colab import files"
      ],
      "metadata": {
        "id": "cXRWNSGf3Adr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "rURNO-SA1b7X",
        "outputId": "8c1c3a55-f34f-4e02-8a66-78995f7dcf51"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a0128d40-e340-4dfe-ae19-18fbd36612bc\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-a0128d40-e340-4dfe-ae19-18fbd36612bc\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving POD_0000.bmp to POD_0000.bmp\n"
          ]
        }
      ],
      "source": [
        "# Take Input\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mounting Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_Vp2AMF19Cu",
        "outputId": "d9021576-f52b-46c4-d9e1-e0fe1fb4a519"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# A data structure that holds block of characters.\n",
        "class PageBlock:\n",
        "    def __init__(self, x1, y1, x2, y2, block_class='textRegion'):\n",
        "        self.x1 = x1\n",
        "        self.y1 = y1\n",
        "        self.x2 = x2\n",
        "        self.y2 = y2\n",
        "        self.block_class = block_class"
      ],
      "metadata": {
        "id": "H7u9RQhe6xIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Part 1 - PreProcessing\n",
        "\n",
        "# A utility function to remove margin\n",
        "def shrink_to_best_fit(img, page_block):\n",
        "\n",
        "    shrink_line = np.all(\n",
        "        img[page_block.y1:page_block.y2+1, page_block.x1:page_block.x2+1] == 0,\n",
        "        axis=1\n",
        "    )\n",
        "\n",
        "    shrink_col = np.all(\n",
        "        img[page_block.y1:page_block.y2+1, page_block.x1:page_block.x2+1] == 0,\n",
        "        axis=0\n",
        "    )\n",
        "\n",
        "    for val in shrink_line:\n",
        "        if val:\n",
        "            page_block.y1 += 1\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    for val in reversed(shrink_line):\n",
        "        if val:\n",
        "            page_block.y2 -= 1\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    for val in shrink_col:\n",
        "        if val:\n",
        "            page_block.x1 += 1\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    for val in reversed(shrink_col):\n",
        "        if val:\n",
        "            page_block.x2 -= 1\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    return page_block\n",
        "\n",
        "\n",
        "def get_processed_img(img):\n",
        "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    _, pros_img = cv2.threshold(\n",
        "        gray_img, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)\n",
        "    return pros_img\n",
        "\n",
        "def plot_array(array):\n",
        "    pp.plot(array)\n",
        "    pp.show()\n",
        "\n",
        "def draw_rectangle(img, page_block_list):\n",
        "\n",
        "    def get_color(block_class):\n",
        "        if (block.block_class == 'figureRegion'):\n",
        "            return (255, 0, 0)\n",
        "        elif (block.block_class == 'formulaRegion'):\n",
        "            return (255, 255, 0)\n",
        "        elif (block.block_class == 'tableRegion'):\n",
        "            return (0, 255, 255)\n",
        "        else:\n",
        "            return (157, 0, 255)\n",
        "\n",
        "    img_copy = img.copy()\n",
        "    for block in page_block_list:\n",
        "        color = get_color(block.block_class)\n",
        "        cv2.rectangle(\n",
        "            img_copy,\n",
        "            (block.x1, block.y1, block.x2-block.x1+1, block.y2-block.y1+1),\n",
        "            color,\n",
        "            1\n",
        "        )\n",
        "\n",
        "    cv2_imshow(img_copy)\n",
        "\n",
        "def get_dilated_img(img, shape, iterations):\n",
        "    # dilate the image to improve vertical projection.\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, shape)\n",
        "    dilate = cv2.dilate(img, kernel, iterations)\n",
        "    # cv2_imshow(dilate)\n",
        "    return dilate\n",
        "\n",
        "def get_column_separator(dilated_img):\n",
        "\n",
        "    #page_block = shrink_to_best_fit(\n",
        "    #   dilated_img,\n",
        "    #    PageBlock(0, 0, dilated_img.shape[1]-1, dilated_img.shape[0]-1)\n",
        "    #)\n",
        "    page_block = PageBlock(0, 0, dilated_img.shape[1]-1, dilated_img.shape[0]-1)\n",
        "\n",
        "    vertical_projection = np.sum(\n",
        "        dilated_img[page_block.y1:page_block.y2 +\n",
        "                    1, page_block.x1:page_block.x2+1],\n",
        "        axis=0\n",
        "    )\n",
        "\n",
        "    #plot_array(vertical_projection)\n",
        "\n",
        "    # find minima in projection\n",
        "    try:\n",
        "        offset = int(page_block.x2/3)\n",
        "\n",
        "        col_sep_list = np.where(\n",
        "            vertical_projection[page_block.x1+offset:page_block.x2-offset] ==\n",
        "            np.amin(vertical_projection[page_block.x1+offset:page_block.x2-offset])\n",
        "        )\n",
        "        # print(offset)\n",
        "        # print(page_block.x1+col_sep_list[0][0])\n",
        "        return offset+col_sep_list[0][0]\n",
        "    except ValueError:\n",
        "        return -1\n",
        "\n",
        "def line_extraction(img, page_block):\n",
        "    partition_list = []\n",
        "\n",
        "    block_horizontal_projection = np.sum(\n",
        "        img[page_block.y1:page_block.y2+1, page_block.x1:page_block.x2+1],\n",
        "        axis=1\n",
        "    )\n",
        "\n",
        "    # plot_array(block_horizontal_projection)\n",
        "\n",
        "    blank_pixel_line_count = 0\n",
        "    y1 = page_block.y1\n",
        "\n",
        "    for val in block_horizontal_projection:\n",
        "        if val == 0:\n",
        "            blank_pixel_line_count += 1\n",
        "        else:\n",
        "            if blank_pixel_line_count >= 1:\n",
        "                partition_list.append(y1-1)\n",
        "            blank_pixel_line_count = 0\n",
        "\n",
        "        y1 += 1\n",
        "\n",
        "    lines = []\n",
        "    cur_y = page_block.y1\n",
        "\n",
        "    for y in partition_list:\n",
        "\n",
        "        page_line = shrink_to_best_fit(\n",
        "            img,\n",
        "            page_block=PageBlock(page_block.x1, cur_y, page_block.x2, y)\n",
        "        )\n",
        "\n",
        "        lines.append(page_line)\n",
        "        cur_y = y+1\n",
        "\n",
        "    page_line = shrink_to_best_fit(\n",
        "        img,\n",
        "        page_block=PageBlock(page_block.x1, cur_y,\n",
        "                             page_block.x2, page_block.y2)\n",
        "    )\n",
        "\n",
        "    lines.append(page_line)\n",
        "\n",
        "    return lines\n",
        "\n",
        "def do_blocks_overlap(left_page_block, right_page_block):\n",
        "    return not(\n",
        "        left_page_block.y2 < right_page_block.y1 or\n",
        "        left_page_block.y1 > right_page_block.y2\n",
        "    )\n",
        "\n",
        "\n",
        "def get_average_space(pros_img, page_block):\n",
        "    dilate = get_dilated_img(\n",
        "        pros_img[page_block.y1:page_block.y2+1, page_block.x1:page_block.x2+1],\n",
        "        shape=(3, 3),\n",
        "        iterations=2\n",
        "    )\n",
        "\n",
        "    vertical_projection = np.sum(dilate, axis=0)\n",
        "\n",
        "    count = 0\n",
        "    times_count = 0\n",
        "    sum_of_space_count = 0\n",
        "\n",
        "    for val in vertical_projection:\n",
        "        if val == 0:\n",
        "            count += 1\n",
        "        else:\n",
        "            if count != 0:\n",
        "                sum_of_space_count += count\n",
        "                count = 0\n",
        "                times_count += 1\n",
        "\n",
        "    if count != 0:\n",
        "        sum_of_space_count += count\n",
        "        count = 0\n",
        "        times_count += 1\n",
        "\n",
        "    if (times_count != 0):\n",
        "        return sum_of_space_count/times_count\n",
        "    else:\n",
        "        # When times count = 0, that signifies there is no space in this line.\n",
        "        # Here we will have to consider that the threshold is equal to the width\n",
        "        # of a single space. Unlike the code above here we are calculating the \n",
        "        # width of a letter.\n",
        "        vertical_projection = np.sum(\n",
        "            pros_img[page_block.y1:page_block.y2 +\n",
        "                     1, page_block.x1:page_block.x2+1],\n",
        "            axis=0\n",
        "        )\n",
        "\n",
        "        count_of_letters = 0\n",
        "        pixels_in_letter = 0\n",
        "        sum_of_pixels_in_letters = 0\n",
        "\n",
        "        for val in vertical_projection:\n",
        "            if val != 0:\n",
        "                pixels_in_letter += 1\n",
        "            else:\n",
        "                if pixels_in_letter != 0:\n",
        "                    count_of_letters += 1\n",
        "                    sum_of_pixels_in_letters += pixels_in_letter\n",
        "                    pixels_in_letter = 0\n",
        "\n",
        "        if pixels_in_letter != 0:\n",
        "            count_of_letters += 1\n",
        "            sum_of_pixels_in_letters += pixels_in_letter\n",
        "\n",
        "        if count_of_letters == 0:\n",
        "            return 0\n",
        "        else:\n",
        "            return sum_of_pixels_in_letters/count_of_letters\n",
        "\n",
        "def develop_lines(pros_img, left_col_lines, right_col_lines):\n",
        "    ordered_lines = []\n",
        "    temp_left_col = []\n",
        "    temp_right_col = []\n",
        "\n",
        "    i = 0\n",
        "    j = 0\n",
        "    while(i < len(left_col_lines) and j < len(right_col_lines)):\n",
        "        left_page_block = left_col_lines[i]\n",
        "        right_page_block = right_col_lines[j]\n",
        "\n",
        "        if (do_blocks_overlap(left_page_block, right_page_block)):\n",
        "\n",
        "            # Average space is considered to be equal to average of space of left\n",
        "            # line + average of space of right line i.e. approx 2 times the width of \n",
        "            # actual space width.\n",
        "            average_space = (get_average_space(pros_img, left_page_block) + get_average_space(pros_img, right_page_block))\n",
        "            short_height_block_difference = min(abs(left_page_block.y2-left_page_block.y1),abs(right_page_block.y2-right_page_block.y1))\n",
        "            long_height_difference = max(abs(left_page_block.y2-left_page_block.y1),abs(right_page_block.y2-right_page_block.y1))\n",
        "            \n",
        "            if (right_page_block.x1 - left_page_block.x2 <= average_space):\n",
        "              if(short_height_block_difference >= (long_height_difference)/2):\n",
        "                  ordered_lines += temp_left_col + temp_right_col\n",
        "\n",
        "                  temp_left_col.clear()\n",
        "                  temp_right_col.clear()\n",
        "                  ordered_lines.append(\n",
        "                        PageBlock(\n",
        "                            x1=left_page_block.x1,\n",
        "                            y1=min(left_page_block.y1, right_page_block.y1),\n",
        "                            x2=right_page_block.x2,\n",
        "                            y2=max(left_page_block.y2, right_page_block.y2)\n",
        "                        )\n",
        "                    )\n",
        "                  i+=1\n",
        "                  j+=1\n",
        "              #Height Difference is more \n",
        "              else :\n",
        "                  if(left_page_block.y2 < right_page_block.y2):\n",
        "                    temp_left_col.append(left_page_block)\n",
        "                    i += 1\n",
        "                  else:\n",
        "                    temp_right_col.append(right_page_block)\n",
        "                    j += 1\n",
        "            #Average Space is not matched\n",
        "            else :\n",
        "                if(left_page_block.y2 < right_page_block.y2):\n",
        "                    temp_left_col.append(left_page_block)\n",
        "                    i += 1\n",
        "                else:\n",
        "                    temp_right_col.append(right_page_block)\n",
        "                    j += 1\n",
        "\n",
        "        # No OverLapping  \n",
        "        elif (left_page_block.y2 < right_page_block.y1):\n",
        "            temp_left_col.append(left_page_block)\n",
        "            i += 1\n",
        "        else:\n",
        "            temp_right_col.append(right_page_block)\n",
        "            j += 1\n",
        "\n",
        "    while (i < len(left_col_lines)):\n",
        "        temp_left_col.append(left_col_lines[i])\n",
        "        i += 1\n",
        "\n",
        "    while (j < len(right_col_lines)):\n",
        "        temp_right_col.append(right_col_lines[j])\n",
        "        j += 1\n",
        "\n",
        "    ordered_lines += temp_left_col + temp_right_col\n",
        "\n",
        "    return ordered_lines\n",
        "\n",
        "\n",
        "def do_preprocessing(filename):\n",
        "\n",
        "    img = cv2.imread(filename)\n",
        "\n",
        "    pros_img = get_processed_img(img)\n",
        "\n",
        "    dilate = get_dilated_img(pros_img, shape=(5, 5), iterations=4)\n",
        "\n",
        "    col_separator = get_column_separator(dilate)\n",
        "\n",
        "    if (col_separator == -1):\n",
        "        return []\n",
        "\n",
        "    left_page_block = shrink_to_best_fit(\n",
        "        pros_img,\n",
        "        page_block=PageBlock(0, 0, col_separator, pros_img.shape[0])\n",
        "    )\n",
        "\n",
        "    right_page_block = shrink_to_best_fit(\n",
        "        pros_img,\n",
        "        page_block=PageBlock(col_separator+1, 0,\n",
        "                             pros_img.shape[1], pros_img.shape[0])\n",
        "    )\n",
        "\n",
        "    left_col_lines = line_extraction(pros_img, left_page_block)\n",
        "    right_col_lines = line_extraction(pros_img, right_page_block)\n",
        "\n",
        "    human_read_lines = develop_lines(pros_img, left_col_lines, right_col_lines)\n",
        "\n",
        "    #draw_rectangle(img, human_read_lines)\n",
        "\n",
        "    return human_read_lines\n"
      ],
      "metadata": {
        "id": "wgg1SdpV5O3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = cv2.imread('POD_0000.bmp')\n",
        "#cv2_imshow(image_name)"
      ],
      "metadata": {
        "id": "M06atPMI8afC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pystruct.utils import SaveLogger\n",
        "saved_unary_model_path = \"drive/MyDrive/btp-dataset/SavedModels/unary/\"\n",
        "saved_pairwise_model_path = \"drive/MyDrive/btp-dataset/SavedModels/pairwise/\"\n",
        "saved_crf_model_path = \"drive/MyDrive/btp-dataset/SavedModels/crf/\"\n",
        "prepared_unannotation_folder_path = \"drive/MyDrive/btp-dataset/Example/\""
      ],
      "metadata": {
        "id": "-KbCcqhoFQqn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unannotated_lines = do_preprocessing('POD_0000.bmp')\n",
        "#print(unannotated_lines)\n",
        "#draw_rectangle(image_name, unannotated_lines)\n",
        "data = {}\n",
        "data['lines'] = []\n",
        "for line in unannotated_lines:\n",
        "  data['lines'].append(\n",
        "      {\n",
        "          'x1': int(line.x1),\n",
        "          'y1': int(line.y1),\n",
        "          'x2': int(line.x2),\n",
        "          'y2': int(line.y2),\n",
        "          'block_class': line.block_class\n",
        "      }\n",
        "  )\n",
        "# print(type(data))\n",
        "json_file = prepared_unannotation_folder_path +'Result.json'\n",
        "# print(json_file)\n",
        "with open(json_file, 'w') as outfile:\n",
        "    json.dump(data, outfile)\n"
      ],
      "metadata": {
        "id": "BHbTs0cm8hl3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "SU9gtFPsNBQk",
        "outputId": "8744f829-3cfb-4d44-8bf0-2a5911a84be6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2f6ceb8f-f0bc-4ea8-8545-c997060780b3\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-2f6ceb8f-f0bc-4ea8-8545-c997060780b3\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Result.json to Result.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.notebook import tqdm\n",
        "import json\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from pystruct.models import EdgeFeatureGraphCRF\n",
        "from pystruct.learners import FrankWolfeSSVM\n",
        "from pystruct.utils import SaveLogger\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, Dense, MaxPooling2D, Flatten\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from keras.metrics import sparse_categorical_crossentropy, categorical_crossentropy\n",
        "from google.colab import drive\n",
        "\n",
        "\n",
        "\n",
        "def scale_img_for_unary(img, x1, x2, y1, y2):\n",
        "\n",
        "    width = x2 - x1 + 1\n",
        "    height = y2 - y1 + 1\n",
        "\n",
        "    final_img = img[y1 : y2 + 1, x1 : x2 + 1]\n",
        "\n",
        "    if width <= 640 and height <= 32:\n",
        "        vertical_padding = 32 - height\n",
        "        horizontal_padding = 640 - width\n",
        "        final_img = cv2.copyMakeBorder(\n",
        "            final_img,\n",
        "            vertical_padding // 2,\n",
        "            vertical_padding // 2 + vertical_padding % 2,\n",
        "            horizontal_padding // 2,\n",
        "            horizontal_padding // 2 + horizontal_padding % 2,\n",
        "            cv2.BORDER_CONSTANT,\n",
        "            None,\n",
        "            (255, 255, 255),\n",
        "        )\n",
        "\n",
        "    elif height <= 32:\n",
        "        scale_down = width / 640\n",
        "        adjusted_height = int(height / scale_down)\n",
        "        final_img = cv2.resize(final_img, (640, adjusted_height))\n",
        "\n",
        "        vertical_padding = 32 - adjusted_height\n",
        "\n",
        "        final_img = cv2.copyMakeBorder(\n",
        "            final_img,\n",
        "            vertical_padding // 2,\n",
        "            vertical_padding // 2 + vertical_padding % 2,\n",
        "            0,\n",
        "            0,\n",
        "            cv2.BORDER_CONSTANT,\n",
        "            None,\n",
        "            (255, 255, 255),\n",
        "        )\n",
        "\n",
        "    elif width <= 640:\n",
        "        scale_down = height / 32\n",
        "        adjusted_width = int(width / scale_down)\n",
        "        final_img = cv2.resize(final_img, (adjusted_width, 32))\n",
        "\n",
        "        horizontal_padding = 640 - adjusted_width\n",
        "\n",
        "        final_img = cv2.copyMakeBorder(\n",
        "            final_img,\n",
        "            0,\n",
        "            0,\n",
        "            horizontal_padding // 2,\n",
        "            horizontal_padding // 2 + horizontal_padding % 2,\n",
        "            cv2.BORDER_CONSTANT,\n",
        "            None,\n",
        "            (255, 255, 255),\n",
        "        )\n",
        "\n",
        "    else:\n",
        "        scale_down_by_width = width / 640\n",
        "        scale_down_by_height = height / 32\n",
        "\n",
        "        if scale_down_by_height < scale_down_by_width:\n",
        "            adjusted_height = int(height / scale_down_by_width)\n",
        "            final_img = cv2.resize(final_img, (640, adjusted_height))\n",
        "            vertical_padding = 32 - adjusted_height\n",
        "\n",
        "            final_img = cv2.copyMakeBorder(\n",
        "                final_img,\n",
        "                vertical_padding // 2,\n",
        "                vertical_padding // 2 + vertical_padding % 2,\n",
        "                0,\n",
        "                0,\n",
        "                cv2.BORDER_CONSTANT,\n",
        "                None,\n",
        "                (255, 255, 255),\n",
        "            )\n",
        "\n",
        "        else:\n",
        "            adjusted_width = int(width / scale_down_by_height)\n",
        "            final_img = cv2.resize(final_img, (adjusted_width, 32))\n",
        "            horizontal_padding = 640 - adjusted_width\n",
        "\n",
        "            final_img = cv2.copyMakeBorder(\n",
        "                final_img,\n",
        "                0,\n",
        "                0,\n",
        "                horizontal_padding // 2,\n",
        "                horizontal_padding // 2 + horizontal_padding % 2,\n",
        "                cv2.BORDER_CONSTANT,\n",
        "                None,\n",
        "                (255, 255, 255),\n",
        "            )\n",
        "\n",
        "    return final_img\n",
        "\n",
        "\n",
        "def scale_img_for_pairwise(img, x1, x2, y1, y2):\n",
        "\n",
        "    width = x2 - x1 + 1\n",
        "    height = y2 - y1 + 1\n",
        "\n",
        "    final_img = img[y1 : y2 + 1, x1 : x2 + 1]\n",
        "\n",
        "    if width <= 640 and height <= 16:\n",
        "        vertical_padding = 16 - height\n",
        "        horizontal_padding = 640 - width\n",
        "        final_img = cv2.copyMakeBorder(\n",
        "            final_img,\n",
        "            vertical_padding // 2,\n",
        "            vertical_padding // 2 + vertical_padding % 2,\n",
        "            horizontal_padding // 2,\n",
        "            horizontal_padding // 2 + horizontal_padding % 2,\n",
        "            cv2.BORDER_CONSTANT,\n",
        "            None,\n",
        "            (255, 255, 255),\n",
        "        )\n",
        "\n",
        "    elif height <= 16:\n",
        "        scale_down = width / 640\n",
        "        adjusted_height = int(height / scale_down)\n",
        "        final_img = cv2.resize(final_img, (640, adjusted_height))\n",
        "\n",
        "        vertical_padding = 16 - adjusted_height\n",
        "\n",
        "        final_img = cv2.copyMakeBorder(\n",
        "            final_img,\n",
        "            vertical_padding // 2,\n",
        "            vertical_padding // 2 + vertical_padding % 2,\n",
        "            0,\n",
        "            0,\n",
        "            cv2.BORDER_CONSTANT,\n",
        "            None,\n",
        "            (255, 255, 255),\n",
        "        )\n",
        "\n",
        "    elif width <= 640:\n",
        "        scale_down = height / 16\n",
        "        adjusted_width = int(width / scale_down)\n",
        "        final_img = cv2.resize(final_img, (adjusted_width, 16))\n",
        "\n",
        "        horizontal_padding = 640 - adjusted_width\n",
        "\n",
        "        final_img = cv2.copyMakeBorder(\n",
        "            final_img,\n",
        "            0,\n",
        "            0,\n",
        "            horizontal_padding // 2,\n",
        "            horizontal_padding // 2 + horizontal_padding % 2,\n",
        "            cv2.BORDER_CONSTANT,\n",
        "            None,\n",
        "            (255, 255, 255),\n",
        "        )\n",
        "\n",
        "    else:\n",
        "        scale_down_by_width = width / 640\n",
        "        scale_down_by_height = height / 16\n",
        "\n",
        "        if scale_down_by_height < scale_down_by_width:\n",
        "            adjusted_height = int(height / scale_down_by_width)\n",
        "            final_img = cv2.resize(final_img, (640, adjusted_height))\n",
        "            vertical_padding = 16 - adjusted_height\n",
        "\n",
        "            final_img = cv2.copyMakeBorder(\n",
        "                final_img,\n",
        "                vertical_padding // 2,\n",
        "                vertical_padding // 2 + vertical_padding % 2,\n",
        "                0,\n",
        "                0,\n",
        "                cv2.BORDER_CONSTANT,\n",
        "                None,\n",
        "                (255, 255, 255),\n",
        "            )\n",
        "\n",
        "        else:\n",
        "            adjusted_width = int(width / scale_down_by_height)\n",
        "            final_img = cv2.resize(final_img, (adjusted_width, 16))\n",
        "            horizontal_padding = 640 - adjusted_width\n",
        "\n",
        "            final_img = cv2.copyMakeBorder(\n",
        "                final_img,\n",
        "                0,\n",
        "                0,\n",
        "                horizontal_padding // 2,\n",
        "                horizontal_padding // 2 + horizontal_padding % 2,\n",
        "                cv2.BORDER_CONSTANT,\n",
        "                None,\n",
        "                (255, 255, 255),\n",
        "            )\n",
        "\n",
        "    return final_img\n",
        "\n",
        "\n",
        "def get_unary_class(u):\n",
        "    if u == \"figureRegion\":\n",
        "        return 0\n",
        "    elif u == \"tableRegion\":\n",
        "        return 1\n",
        "    elif u == \"formulaRegion\":\n",
        "        return 2\n",
        "    else:\n",
        "        return 3\n",
        "\n",
        "\n",
        "def get_unary_data_for_page(annotation_filename, cnn=False):\n",
        "    train_samples = []\n",
        "    train_labels = []\n",
        "\n",
        "    #image_filename = annotation_filename[:-4] + \"bmp\"\n",
        "    #img = cv2.imread(image_name)\n",
        "\n",
        "    with open('Result.json', \"r\") as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "        for line in data[\"lines\"]:\n",
        "            try:\n",
        "                x1, y1, x2, y2 = line[\"x1\"], line[\"y1\"], line[\"x2\"], line[\"y2\"]\n",
        "                scaled_line_img = scale_img_for_unary(img, x1, x2, y1, y2)\n",
        "                train_samples.append(scaled_line_img)\n",
        "                train_labels.append(get_unary_class(line[\"block_class\"]))\n",
        "\n",
        "                if cnn and get_unary_class(line[\"block_class\"]) != get_unary_class(\n",
        "                    \"textRegion\"\n",
        "                ):\n",
        "                    train_samples.append(cv2.flip(scaled_line_img, 0))\n",
        "                    train_labels.append(get_unary_class(line[\"block_class\"]))\n",
        "                    train_samples.append(cv2.flip(scaled_line_img, 1))\n",
        "                    train_labels.append(get_unary_class(line[\"block_class\"]))\n",
        "                    train_samples.append(cv2.flip(scaled_line_img, -1))\n",
        "                    train_labels.append(get_unary_class(line[\"block_class\"]))\n",
        "            except Exception as e:\n",
        "                print(e)\n",
        "                pass\n",
        "\n",
        "    return train_samples, train_labels\n",
        "\n",
        "\n",
        "def get_pairwise_class(u, v):\n",
        "    if v == \"textRegion\" and u == \"tableRegion\":\n",
        "        return 0\n",
        "    elif v == \"textRegion\" and u == \"formulaRegion\":\n",
        "        return 1\n",
        "    elif v == \"textRegion\" and u == \"textRegion\":\n",
        "        return 2\n",
        "    elif v == \"textRegion\" and u == \"figureRegion\":\n",
        "        return 3\n",
        "    elif v == \"tableRegion\" and u == \"tableRegion\":\n",
        "        return 4\n",
        "    elif v == \"tableRegion\" and u == \"formulaRegion\":\n",
        "        return 5\n",
        "    elif v == \"tableRegion\" and u == \"textRegion\":\n",
        "        return 6\n",
        "    elif v == \"tableRegion\" and u == \"figureRegion\":\n",
        "        return 7\n",
        "    elif v == \"figureRegion\" and u == \"tableRegion\":\n",
        "        return 8\n",
        "    elif v == \"figureRegion\" and u == \"formulaRegion\":\n",
        "        return 9\n",
        "    elif v == \"figureRegion\" and u == \"textRegion\":\n",
        "        return 10\n",
        "    elif v == \"figureRegion\" and u == \"figureRegion\":\n",
        "        return 11\n",
        "    elif v == \"formulaRegion\" and u == \"tableRegion\":\n",
        "        return 12\n",
        "    elif v == \"formulaRegion\" and u == \"formulaRegion\":\n",
        "        return 13\n",
        "    elif v == \"formulaRegion\" and u == \"textRegion\":\n",
        "        return 14\n",
        "    elif v == \"formulaRegion\" and u == \"figureRegion\":\n",
        "        return 15\n",
        "    else:\n",
        "        return -1\n",
        "\n",
        "\n",
        "def get_pairwise_data_for_page(annotation_filename):\n",
        "    train_samples = []\n",
        "    train_labels = []\n",
        "    #image_filename = annotation_filename[:-4] + \"bmp\"\n",
        "    #img = cv2.imread(image_name)\n",
        "\n",
        "    with open('Result.json', \"r\") as f:\n",
        "        data = json.load(f)\n",
        "        line_list = data[\"lines\"]\n",
        "\n",
        "        for i in range(len(line_list) - 1):\n",
        "            try:\n",
        "                y11, x11 = line_list[i][\"y1\"], line_list[i][\"x1\"]\n",
        "                y12, x12 = line_list[i][\"y2\"], line_list[i][\"x2\"]\n",
        "                y21, x21 = line_list[i + 1][\"y1\"], line_list[i + 1][\"x1\"]\n",
        "                y22, x22 = line_list[i + 1][\"y2\"], line_list[i + 1][\"x2\"]\n",
        "                scaled_img1 = scale_img_for_pairwise(img, x11, x12, y11, y12)\n",
        "                scaled_img = scale_img_for_pairwise(img, x21, x22, y21, y22)\n",
        "                scaled_img1 = cv2.resize(img[y11 : y12 + 1, x11 : x12 + 1], (640, 16))\n",
        "                scaled_img2 = cv2.resize(img[y21 : y22 + 1, x21 : x22 + 1], (640, 16))\n",
        "                scaled_line_img = cv2.vconcat([scaled_img1, scaled_img2])\n",
        "\n",
        "                train_samples.append(scaled_line_img)\n",
        "                train_labels.append(\n",
        "                    get_pairwise_class(\n",
        "                        line_list[i][\"block_class\"], line_list[i + 1][\"block_class\"]\n",
        "                    )\n",
        "                )\n",
        "            except Exception as e:\n",
        "                pass\n",
        "    return train_samples, train_labels\n",
        "\n",
        "\n",
        "def get_unary_potentials(x):\n",
        "    unary_potentials = []\n",
        "    unary = tf.keras.models.load_model(saved_unary_model_path)\n",
        "    for t in x:\n",
        "        t = np.expand_dims(t, axis=0)\n",
        "        p = unary.predict(t, verbose=0)\n",
        "        unary_potentials.append(np.array(p[0]))\n",
        "        # print(np.shape(p))\n",
        "    return unary_potentials\n",
        "\n",
        "\n",
        "def get_pairwise_potentials(x):\n",
        "    pairwise_potentials = []\n",
        "    pairwise = tf.keras.models.load_model(saved_pairwise_model_path)\n",
        "    for t in x:\n",
        "        t = np.expand_dims(t, axis=0)\n",
        "        pairwise_potentials.append(np.array(pairwise.predict(t, verbose=0)[0]))\n",
        "    return pairwise_potentials\n",
        "\n",
        "\n",
        "# def get_crf_training_data():\n",
        "#     # We have 1600 files, first 1280 are for training.\n",
        "#     x_train = []\n",
        "#     y_train = []\n",
        "\n",
        "#     list_of_files = os.listdir(train_prepared_annotation_folder_path)\n",
        "#     total_number_of_files = 300\n",
        "#     file_counter = 0\n",
        "#     with tqdm(total=total_number_of_files) as pbar:\n",
        "#         for i in range(total_number_of_files):\n",
        "#             annotation_filename = list_of_files[i]\n",
        "#             file_counter += 1\n",
        "\n",
        "#             x_train_u, y_train_u = get_unary_data_for_page(\n",
        "#                 annotation_filename, cnn=False\n",
        "#             )\n",
        "#             x_train_p, _ = get_pairwise_data_for_page(annotation_filename)\n",
        "#             unary_potential_list = np.array(get_unary_potentials(x_train_u))\n",
        "\n",
        "#             pairwise_potential_list = np.array(get_pairwise_potentials(x_train_p))\n",
        "\n",
        "\n",
        "#             n_nodes = len(unary_potential_list)\n",
        "#             edges = np.transpose(\n",
        "#                 np.vstack([np.arange(n_nodes - 1), np.arange(1, n_nodes)])\n",
        "#             )\n",
        "\n",
        "#             if (\n",
        "#                 np.shape(unary_potential_list)[0] - 1\n",
        "#                 == np.shape(pairwise_potential_list)[0]\n",
        "#                 and np.shape(y_train_u)[0] == np.shape(unary_potential_list)[0]\n",
        "#             ):\n",
        "\n",
        "#                 x_train.append((unary_potential_list, edges, pairwise_potential_list))\n",
        "#                 y_train.append(np.array(y_train_u))\n",
        "\n",
        "#             pbar.update(1)\n",
        "\n",
        "#     return x_train, y_train"
      ],
      "metadata": {
        "id": "U186eN-iAmh9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_crf_testing_data():\n",
        "  # We have 1600 files, first 1280 are for training.\n",
        "  x_test = []\n",
        "  y_test = []\n",
        "\n",
        "  list_of_files = os.listdir(prepared_unannotation_folder_path)\n",
        "  total_number_of_files = len(list_of_files)\n",
        "  file_counter = 0\n",
        "  with tqdm(total=total_number_of_files) as pbar:\n",
        "    for i in range(total_number_of_files):\n",
        "      annotation_filename = list_of_files[i]\n",
        "      file_counter += 1\n",
        "\n",
        "      x_test_u, y_test_u = get_unary_data_for_page(annotation_filename, cnn=False)\n",
        "      x_test_p, _ = get_pairwise_data_for_page(annotation_filename)\n",
        "      unary_potential_list = np.array(get_unary_potentials(x_test_u))\n",
        "      pairwise_potential_list = np.array(get_pairwise_potentials(x_test_p))\n",
        "      \n",
        "      n_nodes = len(unary_potential_list)\n",
        "      edges = np.transpose(np.vstack([np.arange(n_nodes - 1), np.arange(1, n_nodes)]))\n",
        "      if(np.shape(unary_potential_list)[0] - 1 == np.shape(pairwise_potential_list)[0] and np.shape(y_test_u)[0]==np.shape(unary_potential_list)[0]):\n",
        "\n",
        "        x_test.append((unary_potential_list, edges, pairwise_potential_list))\n",
        "        y_test.append(np.array(y_test_u))\n",
        "    \n",
        "      pbar.update(1)\n",
        "\n",
        "  return x_test, y_test"
      ],
      "metadata": {
        "id": "MeJMgfkTA4fb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sv = SaveLogger(saved_crf_model_path+'crf_model')\n",
        "ssvm = sv.load()\n",
        "x_test, y_test = get_crf_testing_data()\n",
        "score = ssvm.score(x_test, y_test)\n",
        "print(score)\n",
        "y = ssvm.predict(x_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "a7f33cfe4fd643f08783c22c3a921279",
            "ac10e0f757044bd39f373044a4b60103",
            "2a78e6f0cab94eb9b456966ab028af9d",
            "550e5a6431b34539bbe91ddfd0a484b0",
            "43df045ac42b4717a51c09b68fba2cbf",
            "68eda61cdfd949b4a0b7d8b6a7575d04",
            "0e6a0872ed154266af6f5a8c7680875e",
            "9b83a0f030d4497e8e196a2496162f4b",
            "0fcca2fbd197430f83fa0444fa3bc986",
            "a5afa6f2c493490fbe84a3f5f8dadfd4",
            "430162f98ae5465090b276c2e35aabe3"
          ]
        },
        "id": "TEG-kT6r-jmL",
        "outputId": "7f819bd5-e4a6-4cdb-8cf0-edf2e4810d54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a7f33cfe4fd643f08783c22c3a921279"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y)\n",
        "print(y_test)"
      ],
      "metadata": {
        "id": "1gE_XeY5C2XM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(y))\n",
        "print(y[0])\n",
        "# print(np.shape(y[0]))\n",
        "# print(np.shape(x_test[0][0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgcwjvD5_soQ",
        "outputId": "4fc3508b-500e-45fe-ff2b-64e8a68dd97d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'>\n",
            "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fmujjzbARhrx",
        "outputId": "3d126405-8c6e-4c77-ec3e-3ed62b46bad5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'lines': [{'x1': 199, 'y1': 132, 'x2': 907, 'y2': 146, 'block_class': 'textRegion'}, {'x1': 212, 'y1': 195, 'x2': 895, 'y2': 332, 'block_class': 'textRegion'}, {'x1': 211, 'y1': 337, 'x2': 894, 'y2': 475, 'block_class': 'textRegion'}, {'x1': 539, 'y1': 488, 'x2': 558, 'y2': 504, 'block_class': 'textRegion'}, {'x1': 466, 'y1': 518, 'x2': 637, 'y2': 527, 'block_class': 'textRegion'}, {'x1': 382, 'y1': 532, 'x2': 722, 'y2': 752, 'block_class': 'textRegion'}, {'x1': 501, 'y1': 757, 'x2': 574, 'y2': 764, 'block_class': 'textRegion'}, {'x1': 539, 'y1': 780, 'x2': 558, 'y2': 796, 'block_class': 'textRegion'}, {'x1': 198, 'y1': 825, 'x2': 906, 'y2': 844, 'block_class': 'textRegion'}, {'x1': 197, 'y1': 851, 'x2': 907, 'y2': 868, 'block_class': 'textRegion'}, {'x1': 197, 'y1': 876, 'x2': 302, 'y2': 893, 'block_class': 'textRegion'}, {'x1': 198, 'y1': 936, 'x2': 364, 'y2': 953, 'block_class': 'textRegion'}, {'x1': 374, 'y1': 935, 'x2': 407, 'y2': 954, 'block_class': 'textRegion'}, {'x1': 228, 'y1': 966, 'x2': 905, 'y2': 985, 'block_class': 'textRegion'}, {'x1': 197, 'y1': 998, 'x2': 907, 'y2': 1015, 'block_class': 'textRegion'}, {'x1': 198, 'y1': 1029, 'x2': 907, 'y2': 1046, 'block_class': 'textRegion'}, {'x1': 197, 'y1': 1060, 'x2': 907, 'y2': 1077, 'block_class': 'textRegion'}, {'x1': 197, 'y1': 1091, 'x2': 907, 'y2': 1108, 'block_class': 'textRegion'}, {'x1': 198, 'y1': 1121, 'x2': 907, 'y2': 1140, 'block_class': 'textRegion'}, {'x1': 198, 'y1': 1152, 'x2': 907, 'y2': 1171, 'block_class': 'textRegion'}, {'x1': 197, 'y1': 1184, 'x2': 907, 'y2': 1201, 'block_class': 'textRegion'}, {'x1': 197, 'y1': 1215, 'x2': 907, 'y2': 1232, 'block_class': 'textRegion'}, {'x1': 197, 'y1': 1246, 'x2': 907, 'y2': 1263, 'block_class': 'textRegion'}]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for files in y:\n",
        "  for i in files:\n",
        "    print(type(i))"
      ],
      "metadata": {
        "id": "b5hwBIWHUeuP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def label(img,data):\n",
        "  list_of_boxes = len(y)\n",
        "  i = 0\n",
        "  for file in y:\n",
        "    for label in file:\n",
        "      if label == 0:\n",
        "        data['lines'][i]['block_class'] = \"figureRegion\"\n",
        "        i+=1\n",
        "      elif label == 1:\n",
        "        data['lines'][i]['block_class'] = \"tableRegion\"\n",
        "        i+=1\n",
        "      elif label == 2:\n",
        "        data['lines'][i]['block_class'] = \"formulaRegion\"\n",
        "        i+=1\n",
        "      elif label == 3 :\n",
        "        data['lines'][i]['block_class'] = \"textRegion\"\n",
        "        i+=1\n",
        "\n",
        "  labeled = prepared_unannotation_folder_path +'FinalResult.json'\n",
        "  # print(labeled)\n",
        "  with open(labeled, 'w') as outfile:\n",
        "      json.dump(data, outfile)\n",
        "      "
      ],
      "metadata": {
        "id": "-0EFm1WROa7O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label(img,data)"
      ],
      "metadata": {
        "id": "VIpGulejOvuT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UE54vu40QPHB",
        "outputId": "1082bcf7-2d3d-4230-bf4c-c52a90f4e30a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'lines': [{'x1': 199, 'y1': 132, 'x2': 907, 'y2': 146, 'block_class': 'textRegion'}, {'x1': 212, 'y1': 195, 'x2': 895, 'y2': 332, 'block_class': 'textRegion'}, {'x1': 211, 'y1': 337, 'x2': 894, 'y2': 475, 'block_class': 'textRegion'}, {'x1': 539, 'y1': 488, 'x2': 558, 'y2': 504, 'block_class': 'textRegion'}, {'x1': 466, 'y1': 518, 'x2': 637, 'y2': 527, 'block_class': 'textRegion'}, {'x1': 382, 'y1': 532, 'x2': 722, 'y2': 752, 'block_class': 'textRegion'}, {'x1': 501, 'y1': 757, 'x2': 574, 'y2': 764, 'block_class': 'textRegion'}, {'x1': 539, 'y1': 780, 'x2': 558, 'y2': 796, 'block_class': 'textRegion'}, {'x1': 198, 'y1': 825, 'x2': 906, 'y2': 844, 'block_class': 'textRegion'}, {'x1': 197, 'y1': 851, 'x2': 907, 'y2': 868, 'block_class': 'textRegion'}, {'x1': 197, 'y1': 876, 'x2': 302, 'y2': 893, 'block_class': 'textRegion'}, {'x1': 198, 'y1': 936, 'x2': 364, 'y2': 953, 'block_class': 'textRegion'}, {'x1': 374, 'y1': 935, 'x2': 407, 'y2': 954, 'block_class': 'textRegion'}, {'x1': 228, 'y1': 966, 'x2': 905, 'y2': 985, 'block_class': 'textRegion'}, {'x1': 197, 'y1': 998, 'x2': 907, 'y2': 1015, 'block_class': 'textRegion'}, {'x1': 198, 'y1': 1029, 'x2': 907, 'y2': 1046, 'block_class': 'textRegion'}, {'x1': 197, 'y1': 1060, 'x2': 907, 'y2': 1077, 'block_class': 'textRegion'}, {'x1': 197, 'y1': 1091, 'x2': 907, 'y2': 1108, 'block_class': 'textRegion'}, {'x1': 198, 'y1': 1121, 'x2': 907, 'y2': 1140, 'block_class': 'textRegion'}, {'x1': 198, 'y1': 1152, 'x2': 907, 'y2': 1171, 'block_class': 'textRegion'}, {'x1': 197, 'y1': 1184, 'x2': 907, 'y2': 1201, 'block_class': 'textRegion'}, {'x1': 197, 'y1': 1215, 'x2': 907, 'y2': 1232, 'block_class': 'textRegion'}, {'x1': 197, 'y1': 1246, 'x2': 907, 'y2': 1263, 'block_class': 'textRegion'}]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V_T-kyILXGOG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PpZpJqul6_w1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Lm_nLYkG6_ug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rNS90RuA6_r4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K0FUN_Bk6_pR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pairwise = Sequential([\n",
        "    Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape= (32,640,3)),\n",
        "    Conv2D(filters=32, kernel_size=(3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n",
        "    Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(filters=128, kernel_size=(3, 3), activation='relu'),\n",
        "    Conv2D(filters=128, kernel_size=(3, 3), activation='relu'),\n",
        "    Flatten(),\n",
        "    Dense(1024,activation='relu'),\n",
        "    Dense(16, activation='softmax')\n",
        "])\n",
        "\n",
        "pairwise.summary()"
      ],
      "metadata": {
        "id": "wZAmP_8I6_mr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pairwise.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "r2iWiMTX7Ho0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}